==================================================
TODO list, not at all sorted by priority
==================================================


--------------------------------------------------
Analysis Conditions (Histogram Cuts and more)
--------------------------------------------------

* infinite loop in updateRanks() if a condition uses another condition!!!
  This can not be setup with the final version of the GUI but should still be detected and avoided

* UI: having pending cond link modifications and then changing the analysis in
  some other way (edit op, drag and drop, manual repop) leaves the cond ui in a
  bad state.
  Double click and context menu are disabled for now while there are pending
  condition modifcations but dragging objects still works. Disabling that is a
  pain and also the whole thing is bad and needs a redesign to fix issues like
  this. (e.g. avoid tree repops and instead to tree updates, also have some
  Presenter/Manager object which knows the state of the ui and is responsible
  for keeping everything consistent throughout state changes and repops and
  other modifications)



UI right now:
1 AnalysisWidget
  Per event:
    EventWidget
      2 processing trees per userlevel: ops and sinks

    Toolbar
    ...
  1 ConditionUI
    Per event:
      Condition Tree

treeCount = 2 * sum(userlevels[event] for all events) + 1 * eventCount

Modes: Default, InputSelect, ApplyCondition
Default mode globally highlights broken operators. Selecting a node
highlights inputs and outputs. Drag and drop and copy/paste are enabled.
Full context menu allowing creation of new items in the processing trees.


Create an interface for input selection with
  highlightInputOf(bool enable) / highlightInputSource()
  selectInputFor()
  endSelectInput()
  getEventId()
  getAnalysis()
  getContext()

Pass this to the editor dialogs instead of the EventWidget directly.
Split analysis_ui.cc: event_widget_p.{h,cc} and event_widget.h


Condition/Operator UI interactions:
Default mode:
- select an operator and the active condition is highlighted.
- no changes can be made in this mode
- select any condition and checkboxes appear in the left trees for operators
- to which the condition can be applied to.




* Editing a H2D name via 'F2' is not really possible while a run is active. The
  nodes text will be updated periodically which interferes with editing.
* ExportSink is marked red in the UI. This happens if the optional condition
  input is not connected.
  Also connecting that input immediately clears the red marker but disconnecting
  it again doesn't seem to update the display or for some other reason the
  operator is not colored red again.
* Add tests for rank calculations and condition candidates. I think for
  candicates I'll have to look and the input ranks not at the newly added rank
  itself. The reason is that prior condition application can have added ranks
  in-between.
* Make candidate display instant. Detect if changes have been made and only
  then show the apply and discard buttons.
* Improve the way node content is set/cleared. The same is true for
  highlighting.
* Add good focus handling between the main and condition widgets.
  Does the widget need some indicator? I think right now it's only recognizable
  by finding the current tree selection. Also i believe this breaks when using
  the keyboard to move in a tree.
* Improve how analysis changes are propagated. The analysis ui has to not only
  react to changes made by its own dialogs anymore but also to changes made by
  the h2dwidget.
* Maybe create a system for qwt plot picker handling and related tasks. The
  same might be needed for QwtPlotShapeItems to show and modify cuts
  graphically.
* Deleting a condition keeps it alive in the condlink. Switch to weak_ptr here?
  This will involve calls to lock() sometimes on two objects at the same time,
  e.g. in ConditionLink::operator==()

* Sinks need to be cleared when their condition is applied/removed/modified.

* Add a analysis ui mode description window and indicator somewhere.

* Figure out how compound conditions and the internal dependency ranks work
  together.

* For H1D: [xmin, xmax) range
* For H2D: polygon, sepcial cases: ellipses, rectangles

Values have to be inside the range (1d) or the polygon area (2d) to pass
through the cut. Passing means setting the output or condition flag to true.

-> So far:
* 1d cuts have a single input pipe of size N and N intervals to test against.
  The output is a bitset of size N.

* 2d cuts have two indexed inputs and a polygon or a rectangle to test against.
  The output is a single bit. More geometric shapes (ellipsis) should be added
  if they have simpler hit tests that speed things up and are convenient to use.

Cuts can only be applied after their inputs are available, the same way as
operators can only consume inputs produced earlier. This means cuts have a rank
similar to operators.

Cuts can be applied to anything after they have been processed, not only to the
cuts inputs themselves. For example a h2d could be accumulated only if two
other values fall into a cut defined elsewhere, e.g. "accumulate x and y time
values if x and y energy values are inside this area".

Cut creation: the easiest way is to graphically select two point on a h1d for a
1d cut or to draw a polygon by clicking into a h2d for a 2d cut. This way the
inputs and parameters are known.

Knowing the inputs the rank can be calculated. The gui and logic have to ensure
that only higher ranks can make use of the cut.

Also when viewing any histogram and the cuts parameters are used for the
axis/axes the cut should be displayed again and should (in the future) be
modifiable.

How to show the user which cut is applied to which histogram? The action of
applying a cut could be done via drag and drop or a new kind of input select
mode where the histograms to apply the cut to are clicked.
But after the cut has been applied there's no easy way to graphically see which
cut is active where.

Also: can multiple cuts be applied to the same histo? -> Yes, this could be
done. The histo inputs have to be higher rank than all of the cuts inputs. This
way the cuts have been evaluated at the point where the histo data should be
accumulated. Thus all the cut tests can be performed and ANDed together. One
could even form logical expressions using cuts.

Condition/Cut implementation plan and next steps
------------------------------------------------
* Ability to create/edit interval conditions graphically in a 1d histogram.

  Creating a 1d cut is easy: the user picks two points and they are used to
  generate the intervals for the complete input array.

  Editing is a bit harder: individual intervals should be adjustable via the UI
  but it should also be possible to bunch edit all the array values.

  Also editing must be explicitly started either by selecting the cut in the
  ConditionWidget or having a list of cuts that can be edited inside the
  Histo1DWidget. The reason is that multiple cuts can be defined using the same
  input data so there's no 1:1 match between cuts and histograms.

  -> First implementation: make cuts editable by clicking in the
  ConditionWindow. Figure out which histogram displays the cuts input data and
  open it. Tell the histo widget to edit the specific cut.

* Ability to create/edit rectangle and polygon ConditionOperators graphically using
  the histo widgets.

  Creation is the same as for 1d cuts: the user picks points (for polygon) or
  creates a rectangle/ellipse by dragging/clicking and the cut is created.

  Editing is the same as for 1d cuts: inside the widget a list of possible cuts
  has to be presented otherwise editing can be started from the ConditionWindow.

* Applying cuts to operators:
  A cut is selected in the cut window. in case of interval cuts a specific
  index has to be selected.

  The user now wants to apply the cut and uses the context menu or a button in
  the condition window. This changes the mode of the eventwidget to
  "ApplyCondition". In this mode operators that can make use of the condition
  show a checkbox which can be used to apply the condition.

---------------------
* Clean up the histo widgets. Add a real GUI for cut creation, editing and
  display.

* Create a condition display widget where a list of conditions is shown. When
  selecting a normal operator the active cut should be highlighted. On
  selecting a cut the dependent operators should be highlighted.  Probably
  should make this a tree as boolean compound conditions could be display as a
  tree. This would mean that conditions can appear multiple times in different
  places in the cut tree.

  Another structuring element are input ranks.

* Add logic to figure out if a certain cut can be graphically displayed in a
  given histogram. If so allow showing the cut there.

* Add debugging helpers for cuts. During single event stepping the individual
  bits of the cuts should be inspectable.

* Clean up the histo widgets. Add a real GUI for cut creation, editing and
  display.

* Create a condition display widget where a list of conditions is shown. When
  selecting a normal operator the active cut should be highlighted. On
  selecting a cut the dependent operators should be highlighted.  Probably
  should make this a tree as boolean compound conditions could be display as a
  tree. This would mean that conditions can appear multiple times in different
  places in the cut tree.

  Another structuring element are input ranks.

* Add logic to figure out if a certain cut can be graphically displayed in a
  given histogram. If so allow showing the cut there.

* Add debugging helpers for cuts. During single event stepping the individual
  bits of the cuts should be inspectable.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

--------------------------------------------------
BUGS
--------------------------------------------------
* When enlarging the input of a calibration operator now limtis will be set for
  the newly added indexes. NAN is used for the limits which creates probelms
  further down the line. On rebulding the Calibration check if the internal
  calibration array needs to grow and if so copy the first parameters limits
  over to the new parameters.

* After renaming an object resort the tree it is contained in.

* Add a refresh button to the ui. (same a repop right now, just with a nicer icon :)

* SIS: when not connected and doing an Init Module mvme hangs in recvfrom()

* HtmlDelegate doesn't seem to know how wide the rendered contents are.
  Resizing the column by double clicking the headerview separator chooses a
  width that's too small.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* Add new data sources yielding:
  - the current timetick value (1s granularity, paramvector of size 1)
  - the current event #

* Doc: add ListFilterExtractor to Data Sources
* DAQ Start and then immediately pressing "Run script" in the debug window
  causes a crash.
* Debug CBUS functionality: MDPP-16 doesn't get a CBUS result after leaving DAQ
  mode. It's needs a write to the reset register to make it work again. Why?

* if loading a config file fails when opening a filename from the
  mvmeworkspace.ini file show an explicit error message about the filename in
  the ini possibly being wrong.

* void Histo1DWidgetPrivate::calibApply()
  void Histo1DWidgetPrivate::calibResetToFilter()
  Change them to make use of the improved analysis rebuild mechanism

* JSON RPC: add info about SIS hostname/IP and firmware revision and VMUSB usb
  port and firmware.

* Try to get rid of the module assignment dialog. Instead use the "unassigned"
  category for data sources, the usual "input is not conneceted -> draw in red"
  way of communicating issues with the operator to the user and drag/drop to
  fix module assignments.

  Problems: events may not match up at all. Right now there's no way to display
  stuff that can't be assigned to a particular VME event. Also cross-event
  drag/drop is not possible in any way right now.

* workspace and vme controller settings and such:
  Roberts use case is: open listfile, try to locally reproduce problems a
  customer has. This means he will in most/all cases have to change the sis
  address or even the controller type to match his local setup. This is
  annoying. Even more of a problem is that after making changes he has to
  change the SIS back to the customer settings if he wants to send them the
  listfile.

  Instead when loading a listfile keep the local controller settings and/or use
  a "dummy" controller.

  My use case: see exactly what the customer is doing: hostname or ip-address,
  jumbo frames, additional controller settings. I sometimes really need this
  info and do not want it to be hidden behind some magic.


* Histo2d res reduction/rendering:
  - Maybe: think about and test the case where the h2d res is larger than the
    pixels in the display area and possibly use a dynamic rrf in this case.

* New Feature: add pause/resume markers and/or absolute timestamps to the listfile.
  This would allow for example splitting the run on pause/resume if the user
  changed settings in-between.

* RPC: limit max request size to something reasonable
* RPC: fork jcon-cpp on github and push local changes there

* Improve the loadAnalysisConfig() and similar callchains. Right now they end
  up in gui_read_json_file() which displays a message box with a generic "could
  not read from" error but nothing specific.
  Return value can be tested by checking for isNull() on the returned document.

* Multievent: figure out how and if the stream processor correctly handles
  modules that are disabled in the vme config.
* FIXME: why does mutli event for the whole event get disabled if one of
  the modules is disabled? This does seem unnecessary.

* in openWorkspace(): figure out if the special handling of the listfile output
  dir is really needed.

* try to apply DRY to analysis and vme config serialization. grep for
  "DAQConfig" and "AnalysisNG" extract that code into functions and update
  callers

* multi output arraymap
* constant generator operator:
  multiple outputs
  stepped each time the event has data (a2_end_event)
  fixed rank of 0 so that these are always stepped first, thus consumers can
  count on having the data be active on the output pipes

* DAQ readout performance: try to make better use of the data buffers.
  Currently one processed controller buffer ends up in the data buffer, which
  means for sis it's only around 1500 bytes.
  Do the following: put events into the same buffer until less than a user-set
  limit is free in the buffer or a specific time interval has passed. Then
  write the buffer to disk and in case of a non-local buffer put it into the
  "full" queue.
  Make sure the condition where an event should still go into a certain buffer
  but the space inside the buffer is not enough is reported properly. In this
  case the user-set limit has to be adjusted.
  Reallocations of the buffer could be done but the case where a buffer is
  enlarged again and again must be avoided.

* a2::Operator_KeepPrevious does not seem to set output limits. Is this bugged?
  Fix the test case if needed.

--------------------------------------------------
ExpressionOperator future design plan
--------------------------------------------------
Additional/Advanced Features:
* user defined functions using the exprtk syntax. SECTION 15 -> function_compositor
  Limited to returning a single scalar value and up to six input parameters
  - function name
  - args and their names
  - code

   // define function koo1(x,y,z) { ... }
   compositor
      .add(function_t()
         .name("koo1")
         .var("x").var("y").var("z")
         .expression("1 + cos(x * y) / z;"));

  -> one function compositor per operator. This also allows to define recursive
  functions and functions that call other "dynamic" functions.

  Also check out the add_auxiliary_symtab() method of the compositor. This
  would allow having access to variables from arbitrary symbol tables in the
  function body definition. -> use the a2 runtime library symbol table with this method.

* persistent / static variables

  Could be used to keep some accumulator or the last N events or the last
  result around in the step script.

  statics would be (re)initialized at compile time and then kept during calls to step.

  To make this work the following is needed:
  for scalars: name and initial value
  for arrays: name and size.

  Then the expression operator can create the variables in the symbol table
  instance and initialize them.
  These variables will only be available in the step expression.
  The size definition of arrays must be done via an expression aswell as that's
  the only way to dynamically get to the input sizes. This script will have the
  same symbol table as the begin expression.

  Alternatively could use a return statement returning pairs of (name,
  variable) and then loop through the variables and create and register the
  appropriate types.

  Which solution is better?


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* 13:22:12: SIS3153 Warning: (buffer #109373) (partialEvent) Unexpected packetStatus: 0x89, expected 0x132. Skipping buffer. (suppressed 105 earlier messages)
  packetStatus 0x132 is not valid! This should wrap.
* SIS readout: received count and Timestamp histo count have a small delta of 1
  up to 3 counts. Figure out where this is coming from.

* listfile writing, MVMEStreamWriterHelper: can writing of the final EndMarker
  be moved into closeEventSection? I was surprised that this had to be done
  manually.

* efficiency: when the efficiency is slightly below 100% the display will still
  show a 1.00 due to rounding. maybe color the number if it's not 100%.

* New Export/ListfileFilter Idea: use an operator to decide whether a full, raw
  VME data event should be copied to an output listfile or be suppressed.
  This is basically a copy and filter operation for listfile with the decision
  being made at an arbitrary point in the analysis for the specific event.
  This needs access to the raw input data.

* Transport more state of the DAQ to the analysis side. Right now the stream
  processor always creates a session auto-save even if the DAQ did not start up
  successfully (e.g. because the controller already was in DAQ mode).  Need to
  set some flags in the stream worker so that it can decide on which actions to
  perform and which to skip.

* zachary use case: splitting data by time: 1st, 2nd and 3rd hour. good system
  to solve these kinds of problems.

* add example of how to extract an extended timestamp (48 bits) from our modules to the documentation

* analysis session auto save: get rid of the errors when auto saving an empty analysis
  HDF5: find a way to make the error reporting work. Currently there's nice console output but nothing else.

* Tell Tino about SIS packet loss detection not being accurately possible
  because of the sequence numbers only appearing before events, which has the
  effect that with partial and/or multievent packets, the number of packets and
  the sequence number do not match 1:1 anymore.

  In the original SIS3153 format this wasn't an issue as there was no buffering
  or partials.

  A real packet number prefix would be ideal.

* Maybe add a session file browser/explorer thingy. Could even allow multiple
  open sessions at once. Make sure histos and other objects clearly show which
  session they belong to.

* Change analysis input selection handling to not modify the involved operators
  directly. Instead create fake input pipes and connect the target operator to
  those. Event better would be to create a clone of the original operator to be
  edited and work on that with fake inputs.
  This way no pausing and/or clearing would have to be done if the user opens
  the editor, clicks around and then cancels.
  Also if only the name or unit info is edited nothing actually would need to
  be rebuild (NOTE: some operators might pull copies of their input unit labels
  or prepare some calculation depending on the limits so be careful with
  this!).


* Fix assertion when building a2 (might lead to corruption or crashes in a
  release build!) in the following scenario:
  - H1DSink is connected to a DataFilter by a direct index connection.
  - The address bit of the filter are edited by the user. The new number of
    address bits is less than the old number.
  - The H1DSink is now connected to an index that doesn't exist anymore.
  - The a2 adapter will assert because no histo is found for the index.
  This also affects other operators. Fix this!

* Rate Monitor Widget:
  - make sure rate values are scaled to the "middle" of the y axis
  - improve time labels: don't show hours and minutes if time scale is less than a minute
  -> This has the problem that if you look at a window of the last 60
  seconds, in a run that's over an hour long you won't see the hour number. You
  lose the information that you're in hour 1 plus x in the run.
    I could check if the scale is past a threshold and then switch the formatting.

    if (elapsed_time > 1 hour)
        set scale for intervals below the hour threshold to show hours
    else
        use a scale that hides the hours

    Does the same problem happen for other intervals?

* All filters: make sure address bits are <= 16. This is a reasonable limit and
  avoids crashes due to wrong inputs into the filter fields.

* VME Script "Run" button: this still blocks the GUI.

--------------------------------------------------------------------------------
Data Export Implementation - ExportSink
--------------------------------------------------------------------------------
More ideas from Robert:
* Make it possible to export multiple events into the same file. This will need
  a way to select data from different events. Also the file needs to contain
  the event number for each record.
* Add a "system" event containing the current timetick count and systems stats,
  rates, etc.

* The export sink needs to log which output file is being written! Right now
  it's all very mysterious.
* (maybe) byte order marking. The bin file are not meant as permanent storage
  but to be consumed by a user program which then stored data in e.g. ROOT
  format.
* (maybe) file magic number
* (maybe) version number

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
* add build date to info window thingy
* Andi has a setup where the "compression" combo box has an empty value. no/fast compression can still be selected but the initial value is empty.
* filters: add option to disable adding the random value (done for listfilters)


* Projection of combined H2D does not update axis scales after the source H1D
  has been recalibrated.
* Changing H1D calibration via its widget clears all histograms. This is not
  needed as only the interpretation of the data in the histo changes. Improve
  this case so that it keeps existing histo data.
  -> Difficult: do_beginRun_forward() is used when applying the calibration
  change. I tried passing keepAnalysisState = true but the histo still got
  cleared.

* add sis3153 firmware update utility to 'extras' directory. Also package and
  install sis library code (maybe). Ask struck if this is allowed.

* Add element wise array multiplication operator and/or a calibration operator
  using slope and offset values.

* add 64 bit DataFilter
* phase out data_filter.h (DataFilter and MultiWordDataFilter). stick to the a2 stuff
* Make mvme internal "system" rates available to the analysis.
  Might split this into VME and Analysis rates. Think about how to feed those
  to the analysis system.
  Make this efficient and easily integrated.

* RateHistory needs to only be kept if the specific rate should be plotted.
  Otherwise if the rate should only be displayed it's enough to keep the last
  (most recent) rate value that was calculated. The GUI should be able to pick
  that up.

  Totals are also interesting and should be displayed alongside rates.

System design:
List / Tree of available counters. Must be able to deal with arrays of known
size, like ModuleCounters[E][M]. On the other hand at runtime it is known how
many events and modules there are so only parts of the arrays have to be
exposed.

Hierarchy is good. Names are good. Serialization of the information to restore
a counter display and the required history buffers is needed.
Then be able to find a RateHistoryBuffer via a "hierarchy path".


readout.bytes
readout.buffers
streamProc.bytes
streamProc.event[0] .. event[N] with N either begin MaxVMEEvents or the actual number of events in the VMEConfig
streamProc.event[0].module[0] with limits being the number of events and the number of modules in that event

accessor function to get the current counter value
accessor function to get the previous counter value
-> delta calc possible
accessor to get calibration variables and unit labels and additional options
accessor to get the RateHistoryBuffer for the specific counter
-> filling the buffer is possible

With a system like this different counters could be updated in different
places, e.g. some counters could be handled entirely in the GUI, others might
be updated iff it's a replay and a timetick section is processed.

The update code needs an efficient way to query the rate monitoring system for
counters it needs to process:

void foo(double sample_value)
{
    // constant during the course of the run
    auto byteRateHandle = get_handle_for("daqtime.streamProc.bytes");

    enter_sample(byteRateHandle, sample_value);
}

// FIXME: where does dt come from? does each "sampler" have to pass its own dt?
void enter_sample(RateHandle handle, double value, double dt_s)
{
    prev = value(handle);
    delta = calc_delta0(value, prev);
    setValue(handle, value);
    setDelta(handle, delta);
    rate = delta / dt;
    rate = calibrate_rate(handle, rate)
    if (auto historyBuffer = get_rate_history_buffer(handle))
    {
        historyBuffer->push_back(rate);
    }
}

void handle_replay_timetick() // somewhere in the MVMEStreamProcessor
{

    for (int ei = 0; ei < MaxVMEEvents; ei++)
    {
        for (int mi = 0; mi < MaxVMEModules; mi++)
        {
            enter_sample()
        }
    }

    if (rate_monitor_enabled_for(handle))
        rate_monitor_sample(
}

Rate Monitoring in the analysis
-------------------------------
Experiment time rates are what's interesting, not the rates achieved during a
replay! This means sampling should happen based on replay timeticks or for periodic events
every time the event is triggered.


* Data sources and types
  - Values from periodically reading out the counter value of a scaler module.  Rate
    calculation and then sampling has to be done using two successive scaler values. The
    result can then be recorded in a RateHistoryBuffer.

    -> Right now something roughly similar can be achieved using Calib, KeepPrevious and
       A-B to calculate a rate.

    -> This functionality could be combined in a RateCalculation operator which could then
       be used as the input for a RateHistorySink.
       This approach would also allow to use the calculated and calibrated rate as the
       input for further operators.

    * How this case plays out:
      VME readout is triggered, data is read and transfered to the analysis.  The
      corresponding analysis event is stepped. DataSources consume the readout data and
      yield output values (processModuleData). Operators are stepped in the EndEvent step,
      where they can consume the data source output values.

      Storing the calculated rate could happen every time the event is trigged. This would
      mean it's synchronous to the analysis stepping process. Also the rate recording
      interval would be the same as the interval at which the event is triggered.
      -> Doing synchronous sampling of the readout values only really makes sense for
      periodic events as otherwise the recording interval could differ immensely.

  - Readout of a module that yields a precalculated rate. No calculation is required, only
    recording of the rate values.
    Calibration might still be desired.

    -> Calibration plus RateSink would meet the requirements. Additionally the remarks for
    the first case above apply: recording can be done synchronously to processing the
    event in the analysis.

  - Extraction filter rates
    This type of rate does not use data values from the readout itself but is sort of a
    meta rate. Calculation can be done using the HitCounts array that's currently part of
    every data source in the analysis.

    -> The calculated rates can serve as input for a RateSink.
    To get a consistent timebase sampling and recording should be based on analysis
    timeticks. I think this means that a better resolution than the timetick one can not
    really be achieved.

FIXME: The case where the fraction of two rates should be monitored as in
Wanpengs tool has not been taken care of.

Input could be a pair of rate samplers. The fraction of the two samplers would
then be treated as a rate itself and accumulated in the history buffer in the
same way as a normal rate.
Be careful with the different rate types as they are updated at different times:
- System rates are currently updated in the gui
- Analysis rate values (Precalculated and CounterDifference) are updated each
  time the event is triggered.
- FlowRates are updated on each timetick which can be wallclock time for DAQ or
  experiment time for a replay.


--------------------------------------------------
Single Stepping and Stream Processing
--------------------------------------------------
* Show if multievent processing is active for an event
* Display buffer context in case of a parse error

* Distinction/difference between a stream and a buffer?
  As a buffer can contain multiple sections or even a complete listfile it is an MVMEStream.
  But an MVMEStream will mostly consist of multiple buffers as generated by the
  readout or from reading a listfile.

* Info to parse an mvme stream and report errors:
  - is multievent enabled for eventIndex N?
  - module header filter strings for (eventIndex, moduleIndex)
  - listfile format version

* State:
  BufferIterator
  EventIterator

* Result information for each step:
  - error?
  - error offset
  - data offsets: event section header, module section header, module data begin, module data end
    [number of this event section], [number of the module sections in the event section]
  Available info from the above: section type, event index

* Approaches to handling a stream:
  - Iterator style
    Create an StreamBufferIterator supplying all required information to parse
    the buffer.
    Call next() on the buffer until the result is atEnd.

  - Callback based
    The user passes in a structure containing callbacks for each section type
    and for module data. Not all callbacks have to be implented as they can be
    set to null.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

--------------------------------------------------
* Remove now unused run-time code from the Analysis classes. Make it clear that
  they're for serialization, internal connectiviy and a2 generation only.

* analysis session / HDF5: errors out when saving and empty analysis session
  - enable the save action only if the analysis is non-empty
  - change the session code to be able to handle empty analyses
  - there are leaks found by the address sanitizer pointing to H5E_get_stack

* cmake: Fix the issue with FindROOT adding to the global cflags. Might be
  fixed by moving everything ROOT related into a subdirectory.

* Get rid of automoc and as it mocs stuff that doesn't need mocing.

* Fix sphinx doc build when using the cmake ninja generator.

* Setup controller outputs (NIM, etc) to be active when DAQ is active and maybe
  more. Do this for both controllers and document and/or log what's being setup.

* Crash in a2_adapter when BinSumDiff inputs don't have the same length

* sis3153 implementation
  * On connect read the stacklist control register to figure out if the sis is
    in autonomous mode. If it is and a controller option "Reset SIS3153 on
    connect" is not set then consider the connection attempt to have failed.
    Reasoning: currently when accidentially connecting to a sis that's in use,
    a reset command will be sent and thus the running DAQ will be stopped. This
    can be quite bad if it happens during a real experiment.

  * Running "Init Module" when disconnected blocks the UI
  * Make the mblt count read commands work with the default data_len_format
    setting. Use the leftshift value of the sis register for this.
    Document the behaviour, maybe change the command to not include the mask
    anymore, etc...
  * Think about the sis3153 counted block read commands. Maybe add a "dialect" to
    vmescript so that the fact that sis3153 does not have a mask operation is
    clear.
  * Fix socket error messages under windows. Use and test the WSA stuff.


* check the case where listfile creation throws an exception. right now this
  results in a communication error with the sis controller when trying to start
  another run after a failed one.

* Fix anaylsis object selection color under win7. It's horrible and the text is
  not readable anymore.

* Improve VMEScriptEditor search:
  Make it get focus under windows and unity
  Make it get focus when hitting ctrl+f again
  Bind "find next" to F3 or something.
  Maybe add "highlight" all.

* Analysis: fix names generated by "generate default filters"

* Analysis: getDisplayName() and getShortName() are not that great. For the
  AggregateOps operator I'd like to display "Aggregate Operations" in the "add
  operator" context menu instead of "sum". Where else is getDisplayName() used?
  -> The above works. What I need now is to change the suggested operator name
  of selecting a different aggregate op. Right now it always appends ".sum".

* Resolution change for 2D combined histograms?
  -> Would have to implement this in a different way: Instead of just looking
  up the data in the corresponding H1D instances I'd have to create a new H2D
  with the desired resolution and insert the source values into that histogram.

* Make a RCbus example including a delay between switchting NIM to cbus mode!

* Implement adding of module specific vme init scripts via the GUI.
  The user should be able to modify the order of init scripts by
  dragging/dropping, remove existing scripts and add new ones.
  Optionally copying of an init script to the same or a different module could
  be implemented.

* Maybe reload the analysis on opening a listfile.
  Without the reload the analysis window can become empty if the listfile
  contains different module uuids than the ones in the analysis. A reload could
  trigger a simple 1->1 import of the module and all would be good again.
  The reload could als trigger opening the import dialog if it requires user
  intervention.

* Logspam still makes the app hang! Fix this!!!

* Histo1D and Histo1DWidget
    * Bug: H1D does not work when unitMin > unitMax
    * Histo1DWidget: zoom out after setHistogram()
      But not when the usage is the one in x- and y-projections where the histo is
      replaced with a similar one.
    * Read up on binning error calculations. See how ROOT does it.

* Analysis and AnalysisUI
    * Open new histograms immediately. Do this when creating a sub-histogram.
      Maybe only if DAQ/Replay is running?
    * Copy/Paste
      - Having the ability to clone operators would allow making editing of
        operators much safer.
        Right now if the user picks another input or clears any input slots the
        analysis has to be paused and restarted and dependent operators
        immediately notice the change. This means even if the user cancels the
        dialog the analysis can have unexpected modifications.
        With cloning a copy of the operator would be created. Selecting and
        clearing inputs would only affect the cloned version of the operator
        (input pipes would not need to be fully connected so the input sources
        do not need to change at all during editing -> half connected state!)

- Add error reporting to VMEConfig and Analysis version conversion and read routines

- Refactor gui_write_json_file() to write_json_file() and use exceptions to report errors.
  Meaning: implement functionality using exceptions and not caring about if
  it's used from the gui or not. Then build and use gui wrappers which show
  messageboxes where needed.

- Add warnings to template loading if there are duplicate module types
- Fix diagnosis window hanging and eating system memory when EOE check is
  active and a lot of errors are occuring

* Check for off-by-one errors in the 2D projection code

* lastlog.log:
  Write every logged message to lastlog.log. Do this in the main thread. Flush
  to disk frequently.
  At startup move lastlog.log to lastlog.1.log.
  Keep 5 logfiles around. 4 -> 5, 3 -> 4, 2 -> 3, 1 -> 2, 0 -> 1



* select input UI: disable other tree highlights while it's active.
* ZIP file support:
  On close:
  - write some user description text file to the zip. "Run description", "Run notes", "DAQ notes"
 - save/saveas/load error reporting

* VMEConfig
    * Allow Adding of VME-Init scripts to modules via the gui!

* EventWidget and AnalysisWidget repopulate:
  - Restore open PipeDisplays:
    Store (ObjectId, OutputIndex) to get the output pipe and (pos, size) to restore the widget.
  - Restore splitter states when recreating event widgets.
  - Restore node expansion state
    Could store QUuids for expanded object nodes and after repop rebuild the
    VoidStar set of expanded nodes by getting the pointers via the ids.
* Analysis structure:
  SourceEntry does not really need the eventId as the moduleId implicitly
  specifies the eventId.
* H1D: Take the median of the visible left and right edges. Subtract that value
  from the calculated statistics values. This is supposed to remove the noise
  to the left and right of a peak.
* HistoViewer: Ability to save filled Histograms to disk and reload them later.
  This will allow using histogram tools (fits, etc.) on loaded histos. It also
  allows comparing histos from different runs etc.
* Calculated listfile size in stats display and size shown by windows explorer
  are not the same at all. Why?
* // FIXME: when using subranges the getBinUnchecked() calculation often yields negative bins. why?
  Verify this does in fact happen.
* DAQStats:
  - add pause/resume
  - figure out why buffers/s never has a fractional part
    -> part of the system. addBuffersRead() and addBytesRead() each call maybeUpdateIntervalCounters().
       If we're reading less than 1 buffer per second the resulting
       bytesPerSecond will be 0 for that interval.
    How to make this better?
- License info needs Apache License for PCG. Maybe others. Check what is needed here!
  Also use info from resources/README
- VMUSB: if there are connect/reconnect errors write them to the log view
  Do this when porting to libusb-1.0 as that should also provide better error messages.
- VMUSB: make the mutex non-recursive!

* GUI
  * add versioning to the GUI state saved via QSettings. If the version changes
    use the default layout instead of restoring a possibly incompatible state.
  * add a "reset gui state" button somewhere

* add ability to add notes to VME/analysis config (maybe other objects too)
* VMEScript: add print command

* Histos:
  * add histogram cuts
  * add histogram fitting

* Mesytec Werbung ^^ Hintergrundbilder, Wasserzeichen, etc. (CSS Theme?)
* threading and vme commands
  * run vme scripts in a separate thread when invoked from the gui

* save and restore the zoom and pan of histograms
* save and restore open histograms
* Fix diagnostics window blocking when there are a lot of error messages being generated.
  -> use the leaky bucket throttle for this
